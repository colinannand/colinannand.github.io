---
title: "Compare Viz to Visitech.ai"
date: "2025-01-15"
always_allow_html: true
image: /images/Annual-Average.png
output:
  md_document:
    variant: gfm
    preserve_yaml: TRUE
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "../projects/_posts") })
description: "Prompted from an interesting conversation."
layout: post
categories:
  - R Markdown
  - Jekyll    
    
---
```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message=FALSE)
lapply(c("data.table", "dplyr","ggplot2","scales", "rmdformats", "kableExtra"), FUN=library, character.only=TRUE, quietly=TRUE)

base_dir <- "/Users/cannand/GitHub/colinannand.github.io" 
base_url <- "/"
fig_path <- "images/" 

knitr::opts_knit$set(base.dir = base_dir, base.url = base_url)
knitr::opts_chunk$set(fig.path = fig_path,
                      cache.path = '../cache/',
                      message=FALSE, warning=FALSE,
                      cache = TRUE) 

```

## Quickly Visualizing Large Scale Open Data
- I want to make a quick comparison between a sizable data sets, and visualization that is simple an intuitive. 
- I'll be using R for this, and comparing to visitech.ai[https://www.visitech.ai/]


### 1. Reading in Data on weather.

```{r read in data}
usa2020 <- fread("https://files.asmith.ucdavis.edu/weather/daily/county_noweight/202001.csv")
dim(usa2020)
```

First Initial Plot
```{r initial plot}

usa2020 %>% 
  filter(st_abb=="CO") %>% 
  mutate(Date = as.Date(date, format="YMD")) %>% 
  ggplot(aes(y=tmax, x=Date))+
    geom_point()+
    geom_line()
  
```

Converting to Farenheit manually

```{r data conversion}
usa2020 %>% 
  filter(st_abb=="CO") %>% 
  mutate(Date = as.Date(date, format="YMD"),
         Farenheit = (tmax*(9/5) + 32)) %>% 
  ggplot(aes(y=Farenheit, x=Date))+
    geom_point()+
    geom_line()

```

### And a quick comparison to the image created by Visitech.ai

![](/images/Annual-Average.png)

### 1. World Development Indicators Data
I chose this one because it's used commonly, has a wide variety of factors, and is further available in a R Dataset:

1. World Bank Group
	1. The World Development Indicators (WDI) is the primary World Bank collection of development indicators, compiled from officially-recognized international sources. It presents the most current and accurate global development data available, and includes national, regional and global estimates.
	2. https://datacatalog.worldbank.org/home
	3. https://datatopics.worldbank.org/world-development-indicators/
	4. Direct CSV URL: https://databank.worldbank.org/data/download/WDI_CSV.zip
	5. Size ~270MB
	6. Version published on HuggingFace.ai 
		- https://huggingface.co/datasets/datonic/world_development_indicators

```{r Word Dev Data}
# Load required libraries
library(WDI)
library(ggplot2)
library(dplyr)
library(scales) # For formatting

# Fetch GDP per capita data for selected countries
countries <- c("USA", "CHN", "IND", "BRA", "ZAF")
data <- WDI(
  country = countries,
  indicator = "NY.GDP.PCAP.CD", # GDP per capita (current US$)
  start = 2000,
  end = 2020
)

# Clean the data for better readability
data_clean <- data %>%
  rename(Country = country, Year = year, GDP_Per_Capita = NY.GDP.PCAP.CD)

# Set a custom color palette for countries
custom_colors <- c("USA" = "#1f77b4", "CHN" = "#ff7f0e", "IND" = "#2ca02c", 
                   "BRA" = "#d62728", "ZAF" = "#9467bd")

# Create a colorful time series plot
ggplot(data_clean, aes(x = Year, y = GDP_Per_Capita, color = Country, group = Country)) +
  geom_line(size = 1.2) + # Line plot for trends
  geom_point(size = 2) +  # Points for each data point
  #scale_color_manual(values = custom_colors) + # Custom colors for each country
  scale_y_continuous(labels = dollar_format()) + # Format y-axis as currency
  labs(
    title = "GDP Per Capita Trends (2000-2020)",
    subtitle = "Data from World Development Indicators",
    x = "Year",
    y = "GDP Per Capita (Current US$)",
    color = "Country"
  ) + 
  #theme_minimal() +
  theme(
    plot.title = element_text(size = 16, face = "bold"),
    plot.subtitle = element_text(size = 12, margin = margin(b = 10)),
    axis.title = element_text(size = 12),
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 10),
    panel.grid.major = element_line(color = "grey80"),
    panel.grid.minor = element_line(color = "grey90")
  ) -> p

p

```



```{r include=FALSE}
# Load necessary libraries
library(tidycensus)
library(tidyverse)
library(sf)

# Set your Census API key (register at https://api.census.gov/data/key_signup.html)
census_api_key("6769da1675fe6f3ea04cbf5bbdd112215a715db5", install = TRUE, overwrite = TRUE)

```

### 2. Census Data
	1. There is a large variety of Census data out there, and I think one of the easiest to work with is the ACS (American Community Survey) which is released in 1 and 5 year batches (these are estimates of populations with varying characteristics). 
	2. As an example, I chose the Selected Economic Characteristics (various job sectors and pay, populations numbers and percentages). 
	3. URL Link:
		1. https://data.census.gov/table/ACSDP1Y2023.DP03?g=010XX00US$0400000 
	4. API Direct Link:
		1. https://api.census.gov/data/2023/acs/acs1/profile?get=group(DP03)&ucgid=pseudo(0100000US$0400000)

```{r plotting code}
# Define variables for job categories in DP03 (adjust based on the latest dataset)
variables <- c(
  "DP03_0038E",  # Management, business, science, and arts occupations
  "DP03_0039E",  # Service occupations
  "DP03_0040E",  # Sales and office occupations
  "DP03_0041E",  # Natural resources, construction, and maintenance occupations
  "DP03_0042E"   # Production, transportation, and material moving occupations
)

# Get data for Colorado
dp03_colorado <- get_acs(
  geography = "state",
  variables = variables,
  state = "CO",
  survey = "acs5",
  year = 2021,
  output = "wide"
)

# Reshape and tidy the data
dp03_tidy <- dp03_colorado %>%
  select(NAME, starts_with("DP03")) %>%
  pivot_longer(
    cols = starts_with("DP03"),
    names_to = "job_category",
    values_to = "estimate"
  )

# Rename job categories for readability
job_labels <- c(
  "DP03_0038E" = "Management, Business, Science & Arts",
  "DP03_0039E" = "Service",
  "DP03_0040E" = "Sales & Office",
  "DP03_0041E" = "Natural Resources, Construction & Maintenance",
  "DP03_0042E" = "Production, Transportation & Material Moving"
)

dp03_tidy <- dp03_tidy %>%
  mutate(job_category = recode(job_category, !!!job_labels))

# Create a bar chart with ggplot
ggplot(dp03_tidy, aes(x = reorder(job_category, estimate), y = estimate, fill = job_category)) +
  geom_col(show.legend = FALSE) +
  coord_flip() +
  labs(
    title = "Worker Population by Job Category in Colorado",
    x = "Job Category",
    y = "Estimated Population"
  ) +
  theme_minimal()+
  theme(
    plot.title = element_text(size = 12, face = "bold"),
    plot.subtitle = element_text(size = 12, margin = margin(b = 10)))+
  scale_y_log10(label=comma)

```



### 3. Example of Facebook Data
4. Facebook Metrics 
	1. Brand specific advertisement metrics, across a variety of pages. 
	2. URL Link: https://archive.ics.uci.edu/dataset/368/facebook+metrics
	3. Format: CSV
	4. Size: ~20 KB
	
```{r Facebook Data}
fbook <- fread("../extdata/dataset_Facebook.csv")
names(fbook) <- gsub(names(fbook), pattern = " ", replacement = "_")
glimpse(fbook)

ggplot(fbook, aes(x=Type, y=Total_Interactions))+
  geom_boxplot(alpha=.5)+
  geom_jitter(aes(size=comment))+
  scale_y_log10()+
  labs(title="Relationship between advertisement post types", 
       caption = "Videos have higher interactions, but photos generate more comments")


```

